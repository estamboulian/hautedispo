Conf haproxy:

global
        log /dev/log    local0
        log /dev/log    local1 notice
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin
        stats timeout 30s
        user haproxy
        group haproxy
        daemon

        # Default SSL material locations
        ca-base /etc/ssl/certs
        crt-base /etc/ssl/private

        # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
        log     global
        mode    http
        option  httplog
        option  dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
        errorfile 400 /etc/haproxy/errors/400.http
        errorfile 403 /etc/haproxy/errors/403.http
        errorfile 408 /etc/haproxy/errors/408.http
        errorfile 500 /etc/haproxy/errors/500.http
        errorfile 502 /etc/haproxy/errors/502.http
        errorfile 503 /etc/haproxy/errors/503.http
        errorfile 504 /etc/haproxy/errors/504.http



frontend kubernetes
    bind *:6443
    mode tcp
    option tcplog
    default_backend k8s-masters

backend k8s-masters
    mode tcp
    balance roundrobin
    option tcp-check
    server cp1 10.1.10.66:6443 check
    server cp2 10.1.10.67:6443 check
    server cp3 10.1.10.69:6443 check





Keepalive:

# Script pour v√©rifier si HAProxy est vivant
vrrp_script chk_haproxy {
    script "killall -0 haproxy" # V√©rifie si le processus existe
    interval 2                  # V√©rifie toutes les 2 secondes
    weight 2                    # Ajoute 2 points de priorit√© si OK
    user root
}

# Configuration de l'instance VRRP
vrrp_instance VI_1 {
    state MASTER           # "MASTER" sur le serveur principal
    interface eth0         # <--- CORRECTION ICI (c'est eth0, pas if35)
    virtual_router_id 51   # ID unique pour ce groupe VRRP
    priority 101           # 101 pour le Master
    advert_int 1

    authentication {
        auth_type PASS
        auth_pass esgi
    }

    virtual_ipaddress {
        10.1.10.7      # Votre VIP
    }

    track_script {
        chk_haproxy
    }
}


Architecture:

1 Haproxy, 3 controle plane et 2 worker

Installer de wordpress avec mysql
Partage NFS



Process de mise √† jour:

üîπ Mise √† jour d‚Äôun cluster Kubernetes HA (kubeadm)
1Ô∏è‚É£ Pr√©-requis

Avant toute mise √† jour :

Sauvegarde du cluster et des applications

Sauvegarde etcd (control-plane)

ETCDCTL_API=3 etcdctl snapshot save snapshot.db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key


V√©rifie que tes manifests, ConfigMaps, Secrets, PV/PVC sont sauvegard√©s

Sauvegarde Longhorn ou autre stockage externe si n√©cessaire

V√©rifier que tous les n≈ìuds sont Ready

kubectl get nodes


Tous doivent √™tre Ready.

Installer la nouvelle version de kubeadm sur tous les n≈ìuds

sudo apt update
sudo apt install -y kubeadm=<nouvelle-version>


Ex: pour passer √† 1.34.5 :

sudo apt install -y kubeadm=1.34.5-00


Mettre √† jour le control-plane principal (un n≈ìud √† la fois)

### Planification

kubeadm upgrade plan


V√©rifie la version actuelle et la version disponible

Note la version cible

Appliquer la mise √† jour kubeadm sur le premier control-plane

sudo kubeadm upgrade apply v1.34.5

kubeadm met √† jour les manifests et les composants control-plane (API server, controller-manager, scheduler)

### Mettre √† jour kubelet et kubectl

sudo apt install -y kubelet=1.34.5-00 kubectl=1.34.5-00
sudo systemctl daemon-reload
sudo systemctl restart kubelet


### V√©rifier le n≈ìud

kubectl get nodes
kubectl get pods -n kube-system


Tous les pods control-plane doivent √™tre Running.

### Mettre √† jour les autres control-plane

R√©p√©ter l‚Äô√©tape 2 un n≈ìud √† la fois.

Kubernetes HA permet de garder le cluster op√©rationnel pendant la mise √† jour d‚Äôun n≈ìud control-plane.

### Mettre √† jour les workers

Installer kubeadm, kubelet et kubectl sur chaque worker

sudo apt install -y kubeadm=1.34.5-00 kubelet=1.34.5-00 kubectl=1.34.5-00
sudo systemctl daemon-reload
sudo systemctl restart kubelet


V√©rifier que le worker rejoint bien le cluster

kubectl get nodes

### Verifier le cluster apr√®s mise √† jour

Tous les n≈ìuds doivent √™tre Ready

Tous les pods du namespace kube-system doivent √™tre Running

Les applications Stateful (Longhorn, StatefulSets) doivent √™tre op√©rationnelles

V√©rifier la version

kubectl version --short

### Post-mise √† jour

V√©rifier le StorageClass et les PV/PVC Longhorn

Tester un d√©ploiement test (ex: StatefulSet 2 r√©plicas)

V√©rifier les endpoints HAProxy si expos√©s


Mettre √† jour un n≈ìud √† la fois, surtout pour HA

Ne pas mettre √† jour kubeadm apr√®s kubelet ‚Üí kubelet doit rester compatible

Faire la mise √† jour hors production si possible, ou avec un drain planifi√©

kubectl drain <node-name> --ignore-daemonsets


puis apr√®s update :

kubectl uncordon <node-name>


Garder un snapshot etcd r√©cent avant chaque upgrade

